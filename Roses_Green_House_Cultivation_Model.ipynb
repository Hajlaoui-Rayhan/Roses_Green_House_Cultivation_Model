{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4SK2+8AsLJ+TP5D+BZSOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hajlaoui-Rayhan/Roses_Green_House_Cultivation_Model/blob/main/Roses_Green_House_Cultivation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asm3PfadPfHX",
        "outputId": "eb33a4ba-7925-4987-8726-a449b8354649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.14.0rc0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.7/489.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (4.9.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow)\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0rc0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.14.0rc0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0rc0 (from tensorflow)\n",
            "  Downloading keras-2.14.0rc0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.66.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2023.7.22)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed keras-2.14.0rc0 tensorboard-2.14.0 tensorflow-2.14.0rc0 tensorflow-estimator-2.14.0rc0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package libcudnn8 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "\u001b[1;31mE: \u001b[0mVersion '8.1.0.77-1+cuda11.2' for 'libcudnn8' was not found\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --pre tensorflow tensorflow_datasets\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Input, Add, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython import display\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "urttA8_RYYIx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(r'/content/sample_data/Roses-greenhouse-cultivation-database-repository-_RosesGreenhDB_.xlsx')\n",
        "\n",
        "print(df)\n",
        "training_data = df.sample(frac=0.8, random_state=25)\n",
        "testing_data = df.drop(training_data.index)\n",
        "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
        "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztX6ecD-jqmB",
        "outputId": "2b57f60b-bcc2-4258-c6bd-04fe31f999cd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     HS (Analog)  L (Lux)  T (°)  CO2 (Analog)  HR (%)  clase\n",
            "0            713     0.83   16.2            76    96.8      1\n",
            "1            717     2.50   16.2            75    96.5      1\n",
            "2            717   561.67   16.1            78    96.7      1\n",
            "3            716   640.00   15.9            79    96.5      1\n",
            "4            718   568.33   16.1            79    96.6      1\n",
            "..           ...      ...    ...           ...     ...    ...\n",
            "348          550   280.83   21.0           153    86.7      4\n",
            "349          549   260.83   20.8           151    84.3      4\n",
            "350          550   215.00   20.6           148    86.3      4\n",
            "351          549   215.83   20.4           151    87.8      4\n",
            "352          544   171.67   20.5           147    90.2      4\n",
            "\n",
            "[353 rows x 6 columns]\n",
            "No. of training examples: 282\n",
            "No. of testing examples: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = training_data.iloc[:, :-1].values\n",
        "y_train = training_data.iloc[:, -1].values - 1  # Convert class labels from 1-4 to 0-3\n",
        "print(X_train)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yr5JmZjkD_u",
        "outputId": "9692b099-478b-4651-f5d8-49e0a96b330e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.010000e+02 5.461250e+04 2.900000e+01 1.590000e+02 6.180000e+01]\n",
            " [5.790000e+02 2.495000e+03 2.160000e+01 1.730000e+02 8.560000e+01]\n",
            " [5.770000e+02 2.797500e+03 2.200000e+01 1.760000e+02 8.430000e+01]\n",
            " ...\n",
            " [7.740000e+02 4.325000e+02 2.100000e+01 1.500000e+02 9.150000e+01]\n",
            " [6.180000e+02 4.026333e+04 2.390000e+01 2.230000e+02 7.510000e+01]\n",
            " [5.300000e+02 1.246083e+04 3.070000e+01 1.890000e+02 7.470000e+01]]\n",
            "[0 3 3 0 1 3 2 2 0 2 3 1 2 2 2 0 3 1 0 1 3 3 1 1 2 3 0 0 0 1 0 0 2 2 0 2 1\n",
            " 1 3 1 1 2 0 3 0 2 2 0 0 3 0 2 1 1 1 1 1 0 1 2 1 2 0 2 0 2 3 1 2 0 0 3 0 0\n",
            " 0 3 0 0 0 0 2 3 2 2 0 2 3 1 0 0 3 0 0 3 3 2 0 0 1 3 3 0 0 0 2 1 3 2 1 2 0\n",
            " 1 2 0 1 2 1 0 0 3 1 0 0 2 0 2 2 2 0 2 0 2 0 0 3 1 0 2 0 0 2 3 1 3 1 1 0 0\n",
            " 3 2 0 1 2 1 3 1 0 1 1 0 0 0 1 2 2 2 0 3 2 2 2 3 3 1 2 0 0 0 0 0 0 2 1 1 2\n",
            " 2 0 3 0 3 3 0 2 2 0 0 0 0 0 1 0 1 1 2 0 0 1 0 2 0 1 3 3 1 2 0 0 0 3 2 2 0\n",
            " 2 0 3 2 0 0 3 1 0 3 2 2 2 2 2 1 0 0 2 2 1 0 0 0 1 2 2 3 1 0 0 1 2 0 2 0 0\n",
            " 3 2 2 1 0 0 1 0 1 0 2 0 1 1 1 1 0 3 0 3 0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters\n",
        "learning_rate = 0.000416\n",
        "num_hidden_layers = 5\n",
        "num_neurons = 265\n",
        "activation_function = 'tanh'\n",
        "batch_size = 36\n",
        "l2_weight_decay = 0.007963\n",
        "num_classes = 4\n",
        "num_features = 5\n",
        "num_iterations = 80"
      ],
      "metadata": {
        "id": "X6RwRw-Fkmcw"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(265, input_shape=(5,), activation='tanh'),\n",
        "    tf.keras.layers.Dense(265, activation='tanh'),\n",
        "    tf.keras.layers.Dense(265, activation='tanh'),\n",
        "    tf.keras.layers.Dense(265, activation='tanh'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "kqf2Kg4coqwt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WZV_00qNo8gn"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, batch_size=36, epochs=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVrHhh-3rACB",
        "outputId": "866ade96-578d-431c-9843-ed571264275f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5057 - accuracy: 0.7411\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5086 - accuracy: 0.7482\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5099 - accuracy: 0.7518\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.5061 - accuracy: 0.7482\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5019 - accuracy: 0.7553\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5066 - accuracy: 0.7411\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5140 - accuracy: 0.7553\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5471 - accuracy: 0.7270\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5277 - accuracy: 0.7482\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5201 - accuracy: 0.7376\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5151 - accuracy: 0.7482\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5101 - accuracy: 0.7482\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5051 - accuracy: 0.7482\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5075 - accuracy: 0.7376\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5140 - accuracy: 0.7447\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4987 - accuracy: 0.7482\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4933 - accuracy: 0.7518\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4914 - accuracy: 0.7518\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4898 - accuracy: 0.7482\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4894 - accuracy: 0.7482\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.4941 - accuracy: 0.7447\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4892 - accuracy: 0.7447\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5159 - accuracy: 0.7411\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5835 - accuracy: 0.7234\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5772 - accuracy: 0.7270\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5709 - accuracy: 0.7234\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5591 - accuracy: 0.7128\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5512 - accuracy: 0.7340\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5432 - accuracy: 0.7270\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.5273 - accuracy: 0.7447\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.5133 - accuracy: 0.7447\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5095 - accuracy: 0.7482\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5121 - accuracy: 0.7447\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.5050 - accuracy: 0.7447\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4899 - accuracy: 0.7518\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4873 - accuracy: 0.7482\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.4840 - accuracy: 0.7553\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.4846 - accuracy: 0.7482\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4797 - accuracy: 0.7553\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4809 - accuracy: 0.7447\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4859 - accuracy: 0.7447\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4805 - accuracy: 0.7553\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4828 - accuracy: 0.7518\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.4865 - accuracy: 0.7589\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4910 - accuracy: 0.7518\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.7518\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4921 - accuracy: 0.7624\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4938 - accuracy: 0.7589\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4848 - accuracy: 0.7553\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5501 - accuracy: 0.7340\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.6793 - accuracy: 0.6809\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.6468 - accuracy: 0.6596\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.6080 - accuracy: 0.6844\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5867 - accuracy: 0.7270\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5783 - accuracy: 0.7199\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.5652 - accuracy: 0.7128\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5524 - accuracy: 0.7163\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5418 - accuracy: 0.7234\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.5277 - accuracy: 0.7234\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5342 - accuracy: 0.7305\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5394 - accuracy: 0.7270\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5459 - accuracy: 0.7270\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5361 - accuracy: 0.7305\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5302 - accuracy: 0.7340\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5164 - accuracy: 0.7376\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5144 - accuracy: 0.7305\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5312 - accuracy: 0.7340\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5183 - accuracy: 0.7234\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5227 - accuracy: 0.7234\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5178 - accuracy: 0.7376\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5310 - accuracy: 0.7482\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5048 - accuracy: 0.7376\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5358 - accuracy: 0.7128\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.5051 - accuracy: 0.7411\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5117 - accuracy: 0.7340\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.5090 - accuracy: 0.7376\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4999 - accuracy: 0.7482\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4909 - accuracy: 0.7482\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4990 - accuracy: 0.7518\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4880 - accuracy: 0.7624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test = testing_data.iloc[:, :-1].values\n",
        "y_test = (testing_data.iloc[:, -1].values - 1)\n",
        "print(X_test)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV9X3Q4x87HQ",
        "outputId": "42c0b268-5cc9-42e9-8d84-5c70f587a723"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.170000e+02 5.616700e+02 1.610000e+01 7.800000e+01 9.670000e+01]\n",
            " [7.880000e+02 2.334170e+03 2.310000e+01 1.580000e+02 7.200000e+01]\n",
            " [7.860000e+02 5.461250e+04 2.800000e+01 1.600000e+02 6.620000e+01]\n",
            " [8.200000e+02 7.863330e+03 2.980000e+01 1.570000e+02 5.950000e+01]\n",
            " [7.630000e+02 1.222500e+03 2.300000e+01 1.560000e+02 8.090000e+01]\n",
            " [7.620000e+02 1.995830e+03 2.310000e+01 1.620000e+02 8.020000e+01]\n",
            " [7.630000e+02 1.860000e+03 2.330000e+01 1.620000e+02 7.910000e+01]\n",
            " [7.730000e+02 2.313330e+03 2.270000e+01 1.490000e+02 8.210000e+01]\n",
            " [7.690000e+02 2.685830e+03 2.260000e+01 1.500000e+02 8.390000e+01]\n",
            " [7.750000e+02 1.377500e+03 2.230000e+01 1.470000e+02 8.510000e+01]\n",
            " [7.760000e+02 9.825000e+02 2.190000e+01 1.490000e+02 8.670000e+01]\n",
            " [7.760000e+02 9.308300e+02 2.170000e+01 1.370000e+02 8.840000e+01]\n",
            " [7.730000e+02 6.958300e+02 2.200000e+01 1.500000e+02 8.760000e+01]\n",
            " [7.730000e+02 2.983300e+02 2.110000e+01 1.480000e+02 9.060000e+01]\n",
            " [7.780000e+02 8.917000e+01 2.040000e+01 1.450000e+02 9.310000e+01]\n",
            " [7.750000e+02 6.750000e+01 2.000000e+01 1.470000e+02 9.430000e+01]\n",
            " [7.690000e+02 7.417000e+01 2.000000e+01 1.460000e+02 9.480000e+01]\n",
            " [7.870000e+02 0.000000e+00 1.950000e+01 1.470000e+02 9.660000e+01]\n",
            " [7.870000e+02 0.000000e+00 1.950000e+01 1.440000e+02 9.580000e+01]\n",
            " [7.880000e+02 0.000000e+00 1.970000e+01 1.490000e+02 9.500000e+01]\n",
            " [1.240000e+02 2.675000e+02 2.320000e+01 4.000000e+01 7.210000e+01]\n",
            " [6.020000e+02 9.115000e+03 2.670000e+01 1.890000e+02 7.650000e+01]\n",
            " [6.000000e+02 1.054083e+04 2.690000e+01 1.860000e+02 7.890000e+01]\n",
            " [5.320000e+02 3.345916e+04 2.350000e+01 2.430000e+02 7.780000e+01]\n",
            " [1.240000e+02 2.675000e+02 2.320000e+01 4.000000e+01 7.210000e+01]\n",
            " [6.020000e+02 9.115000e+03 2.670000e+01 1.890000e+02 7.650000e+01]\n",
            " [6.000000e+02 1.054083e+04 2.690000e+01 1.860000e+02 7.890000e+01]\n",
            " [3.620000e+02 1.266670e+03 2.060000e+01 9.100000e+01 7.310000e+01]\n",
            " [3.610000e+02 1.380000e+03 2.050000e+01 9.000000e+01 7.370000e+01]\n",
            " [3.680000e+02 1.041583e+04 2.250000e+01 1.030000e+02 8.100000e+01]\n",
            " [5.320000e+02 3.345916e+04 2.350000e+01 2.430000e+02 7.780000e+01]\n",
            " [6.020000e+02 9.115000e+03 2.670000e+01 1.890000e+02 7.650000e+01]\n",
            " [1.240000e+02 0.000000e+00 2.300000e+01 3.400000e+01 7.900000e+01]\n",
            " [1.300000e+02 0.000000e+00 2.210000e+01 3.400000e+01 7.290000e+01]\n",
            " [1.300000e+02 0.000000e+00 2.230000e+01 3.600000e+01 7.080000e+01]\n",
            " [3.680000e+02 1.041583e+04 2.250000e+01 1.030000e+02 8.100000e+01]\n",
            " [1.240000e+02 0.000000e+00 2.250000e+01 3.400000e+01 7.130000e+01]\n",
            " [1.240000e+02 0.000000e+00 2.300000e+01 3.400000e+01 7.900000e+01]\n",
            " [1.240000e+02 2.675000e+02 2.320000e+01 4.000000e+01 7.210000e+01]\n",
            " [6.020000e+02 9.115000e+03 2.670000e+01 1.890000e+02 7.650000e+01]\n",
            " [4.400000e+02 7.505850e+03 2.460000e+01 2.000000e+02 7.720000e+01]\n",
            " [4.030000e+02 1.120000e+03 1.840000e+01 7.700000e+01 8.960000e+01]\n",
            " [3.930000e+02 7.616700e+02 1.840000e+01 7.800000e+01 8.920000e+01]\n",
            " [3.670000e+02 3.104170e+03 1.890000e+01 7.900000e+01 8.760000e+01]\n",
            " [4.270000e+02 5.461250e+04 3.650000e+01 9.800000e+01 4.330000e+01]\n",
            " [4.340000e+02 1.124667e+04 4.020000e+01 8.800000e+01 4.020000e+01]\n",
            " [4.490000e+02 1.639417e+04 3.030000e+01 8.600000e+01 4.870000e+01]\n",
            " [4.600000e+02 1.962583e+04 3.110000e+01 7.600000e+01 4.620000e+01]\n",
            " [4.590000e+02 7.630000e+03 2.880000e+01 7.600000e+01 4.920000e+01]\n",
            " [5.460000e+02 1.713167e+04 2.870000e+01 2.010000e+02 7.670000e+01]\n",
            " [5.430000e+02 9.858330e+03 2.840000e+01 1.970000e+02 7.670000e+01]\n",
            " [5.410000e+02 1.572417e+04 2.850000e+01 1.930000e+02 7.540000e+01]\n",
            " [5.350000e+02 9.803330e+03 2.930000e+01 1.830000e+02 7.300000e+01]\n",
            " [4.610000e+02 1.062917e+04 2.910000e+01 7.200000e+01 4.920000e+01]\n",
            " [4.130000e+02 2.003917e+04 2.890000e+01 2.020000e+02 7.780000e+01]\n",
            " [4.410000e+02 1.023917e+04 2.920000e+01 1.870000e+02 7.810000e+01]\n",
            " [5.910000e+02 1.972750e+04 2.820000e+01 1.800000e+02 7.870000e+01]\n",
            " [5.570000e+02 7.458330e+03 2.830000e+01 1.540000e+02 7.240000e+01]\n",
            " [4.710000e+02 5.637500e+03 2.640000e+01 7.000000e+01 5.560000e+01]\n",
            " [4.710000e+02 6.233330e+03 2.590000e+01 7.000000e+01 5.650000e+01]\n",
            " [5.330000e+02 6.809170e+03 2.240000e+01 1.780000e+02 9.200000e+01]\n",
            " [5.340000e+02 7.070000e+03 2.260000e+01 1.780000e+02 9.150000e+01]\n",
            " [5.530000e+02 9.061670e+03 2.330000e+01 1.730000e+02 9.100000e+01]\n",
            " [5.230000e+02 6.806670e+03 2.340000e+01 1.900000e+02 8.060000e+01]\n",
            " [5.600000e+02 3.610000e+03 2.270000e+01 1.830000e+02 8.270000e+01]\n",
            " [5.700000e+02 2.835000e+03 2.230000e+01 1.820000e+02 8.290000e+01]\n",
            " [5.810000e+02 3.422500e+03 2.130000e+01 1.620000e+02 8.860000e+01]\n",
            " [5.550000e+02 2.853330e+03 2.130000e+01 1.580000e+02 8.530000e+01]\n",
            " [5.470000e+02 1.760000e+03 2.090000e+01 1.540000e+02 8.730000e+01]\n",
            " [5.530000e+02 2.052500e+03 2.070000e+01 1.560000e+02 8.680000e+01]\n",
            " [5.520000e+02 2.950000e+03 2.100000e+01 1.540000e+02 8.590000e+01]]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZgD6zmY9jle",
        "outputId": "fe32d205-e768-48ec-ff1b-0a8881b16b2c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "[[9.99998391e-01 2.04775688e-07 2.56267967e-08 1.30674607e-06]\n",
            " [9.99949038e-01 3.96856819e-07 9.46525745e-07 4.95657332e-05]\n",
            " [3.41055721e-01 3.79627854e-01 2.78795540e-01 5.20884292e-04]\n",
            " [2.06640542e-01 2.00613216e-03 1.37079671e-01 6.54273689e-01]\n",
            " [9.99793053e-01 5.67915731e-06 6.71863859e-07 2.00627619e-04]\n",
            " [9.99895155e-01 4.48689065e-07 6.60622391e-07 1.03537757e-04]\n",
            " [9.99548972e-01 4.77702201e-07 5.98745487e-07 4.49981715e-04]\n",
            " [9.99937952e-01 4.89819342e-07 1.16030890e-06 6.03642984e-05]\n",
            " [9.98527229e-01 3.79202793e-05 1.76239002e-04 1.25837256e-03]\n",
            " [9.99981821e-01 6.80619053e-07 1.15120280e-07 1.72598448e-05]\n",
            " [9.99980032e-01 1.97620602e-06 6.81168189e-08 1.77897928e-05]\n",
            " [9.99991119e-01 9.51527227e-07 4.19288924e-08 7.81966082e-06]\n",
            " [9.99985874e-01 9.30760280e-07 5.54308954e-08 1.31308016e-05]\n",
            " [9.96554554e-01 1.31162560e-05 2.48717583e-06 3.42985359e-03]\n",
            " [9.99983728e-01 1.31781485e-06 2.95994596e-07 1.46571138e-05]\n",
            " [9.99983132e-01 1.38739381e-06 3.35103465e-07 1.50450087e-05]\n",
            " [9.99982893e-01 1.40194425e-06 3.40921417e-07 1.52397670e-05]\n",
            " [9.99981344e-01 1.51582753e-06 4.23054985e-07 1.65943493e-05]\n",
            " [9.99982178e-01 1.46225568e-06 3.97125547e-07 1.60070995e-05]\n",
            " [9.99981940e-01 1.48162690e-06 4.04074228e-07 1.62065353e-05]\n",
            " [3.78974860e-08 9.99776602e-01 2.15916720e-04 7.39742154e-06]\n",
            " [6.52187318e-03 2.87173420e-01 4.28761035e-01 2.77543575e-01]\n",
            " [1.62308700e-02 3.00533623e-01 5.68499863e-01 1.14735745e-01]\n",
            " [3.41055691e-01 3.79627854e-01 2.78795540e-01 5.20884583e-04]\n",
            " [3.78974860e-08 9.99776602e-01 2.15916720e-04 7.39742154e-06]\n",
            " [6.52187318e-03 2.87173420e-01 4.28761035e-01 2.77543575e-01]\n",
            " [1.62308700e-02 3.00533623e-01 5.68499863e-01 1.14735745e-01]\n",
            " [8.72655364e-04 3.70883226e-01 6.11423731e-01 1.68203432e-02]\n",
            " [3.30891082e-04 2.93342263e-01 6.96898997e-01 9.42791905e-03]\n",
            " [3.12178768e-03 2.39660755e-01 3.76420051e-01 3.80797386e-01]\n",
            " [3.41055751e-01 3.79627824e-01 2.78795511e-01 5.20884292e-04]\n",
            " [6.52185921e-03 2.87173301e-01 4.28760707e-01 2.77544022e-01]\n",
            " [1.40453471e-08 9.99954164e-01 4.17966985e-05 3.97254826e-06]\n",
            " [1.59453286e-08 9.99957621e-01 3.72229879e-05 5.08929088e-06]\n",
            " [1.94027034e-08 9.99959052e-01 3.41361301e-05 6.75654019e-06]\n",
            " [3.12178768e-03 2.39660755e-01 3.76420051e-01 3.80797386e-01]\n",
            " [1.53940753e-08 9.99957502e-01 3.76507305e-05 4.81737743e-06]\n",
            " [1.40453471e-08 9.99954164e-01 4.17966985e-05 3.97254826e-06]\n",
            " [3.78974860e-08 9.99776602e-01 2.15916720e-04 7.39742154e-06]\n",
            " [6.52187318e-03 2.87173420e-01 4.28761035e-01 2.77543575e-01]\n",
            " [3.06765712e-03 2.38462612e-01 3.76644343e-01 3.81825268e-01]\n",
            " [8.74110758e-02 1.10168457e-01 1.50229499e-01 6.52190924e-01]\n",
            " [4.30699915e-01 1.88313285e-03 6.79654535e-04 5.66737354e-01]\n",
            " [1.88251049e-03 1.34281233e-01 5.29328167e-01 3.34508121e-01]\n",
            " [3.41055721e-01 3.79627854e-01 2.78795540e-01 5.20884292e-04]\n",
            " [1.89145599e-02 2.91385978e-01 5.93768716e-01 9.59308818e-02]\n",
            " [3.03105963e-03 9.91860125e-03 9.86715496e-01 3.34934797e-04]\n",
            " [3.03105963e-03 9.91860125e-03 9.86715496e-01 3.34934797e-04]\n",
            " [1.89145599e-02 2.91385978e-01 5.93768716e-01 9.59308818e-02]\n",
            " [1.89138353e-02 2.91388661e-01 5.93762159e-01 9.59352627e-02]\n",
            " [3.09859496e-03 2.39150047e-01 3.76508921e-01 3.81242394e-01]\n",
            " [1.89113468e-02 2.91398764e-01 5.93739271e-01 9.59506929e-02]\n",
            " [3.83126317e-03 2.53595084e-01 3.78598511e-01 3.63975167e-01]\n",
            " [1.89145599e-02 2.91385978e-01 5.93768716e-01 9.59308818e-02]\n",
            " [3.12184868e-03 1.02220960e-02 9.86318707e-01 3.37294099e-04]\n",
            " [3.06770066e-03 2.38463655e-01 3.76644075e-01 3.81824493e-01]\n",
            " [1.89355686e-02 2.91243494e-01 5.94177485e-01 9.56433043e-02]\n",
            " [7.97961093e-03 2.97236592e-01 4.58220929e-01 2.36562923e-01]\n",
            " [1.89536810e-02 2.91219324e-01 5.94020128e-01 9.58068743e-02]\n",
            " [1.89148225e-02 2.91384667e-01 5.93769968e-01 9.59305316e-02]\n",
            " [3.06765712e-03 2.38462612e-01 3.76644343e-01 3.81825268e-01]\n",
            " [3.06765758e-03 2.38462701e-01 3.76644313e-01 3.81825328e-01]\n",
            " [3.06857447e-03 2.38483265e-01 3.76639992e-01 3.81808162e-01]\n",
            " [3.06766224e-03 2.38462701e-01 3.76644433e-01 3.81825179e-01]\n",
            " [2.63008033e-03 2.01386586e-03 3.45252931e-01 6.50103092e-01]\n",
            " [8.69287737e-03 2.20789836e-04 3.98994312e-02 9.51186955e-01]\n",
            " [7.84039591e-03 2.17643435e-04 5.08745536e-02 9.41067398e-01]\n",
            " [8.58965982e-03 2.22701536e-04 4.02900688e-02 9.50897574e-01]\n",
            " [5.80020994e-02 2.67069452e-02 7.99930468e-02 8.35297942e-01]\n",
            " [9.06326063e-03 8.95085186e-03 6.70800880e-02 9.14905727e-01]\n",
            " [8.34965799e-03 2.27350247e-04 4.12470512e-02 9.50175881e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=np.argmax(predictions, axis=1)\n",
        "\n",
        "print(predictions)\n",
        "confusion_mtx = tf.math.confusion_matrix(y_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0rkzom8--9H",
        "outputId": "f7fd2879-4f42-48da-965c-2bdb00135053"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 1 1 2 2 2 2 3 1 2 1 1 1 3 1\n",
            " 1 1 2 3 3 3 2 1 2 2 2 2 2 3 2 2 2 2 3 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx,\n",
        "            xticklabels=['0','1','2','3'],\n",
        "            yticklabels=['0','1','2','3'],\n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "cJY-40g-HdjL",
        "outputId": "e889aabe-2d14-42b0-b353-79a91c7e2ea4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('rose_predictor.h5')"
      ],
      "metadata": {
        "id": "SCMMQqovRlyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4558cc8-4beb-4a73-94bf-3d2b177be652"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open('rose_predictor'+ '.tflite','wb').write(tflite_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72jTGq9SSARe",
        "outputId": "f146d569-b133-48da-d1e7-c52fb7edc384"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221024"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Convert some hex value into an array for C programming\n",
        "def hex_to_c_array(hex_data, var_name):\n",
        "\n",
        "  c_str = ''\n",
        "\n",
        "  # Create header guard\n",
        "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
        "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
        "\n",
        "  # Add array length at top of file\n",
        "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
        "\n",
        "  # Declare C variable\n",
        "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
        "  hex_array = []\n",
        "  for i, val in enumerate(hex_data) :\n",
        "\n",
        "    # Construct string from hex\n",
        "    hex_str = format(val, '#04x')\n",
        "\n",
        "    # Add formatting so each line stays within 80 characters\n",
        "    if (i + 1) < len(hex_data):\n",
        "      hex_str += ','\n",
        "    if (i + 1) % 12 == 0:\n",
        "      hex_str += '\\n '\n",
        "    hex_array.append(hex_str)\n",
        "\n",
        "  # Add closing brace\n",
        "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
        "\n",
        "  # Close out header guard\n",
        "  c_str += '#endif //' + var_name.upper() + '_H'\n",
        "\n",
        "  return c_str\n",
        ""
      ],
      "metadata": {
        "id": "1wI8D1xbe9-0"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write TFLite model to a C source (or header) file\n",
        "with open('rose_c_model' + '.h', 'w') as file:\n",
        "  file.write(hex_to_c_array(tflite_model, 'rose_c_model'))"
      ],
      "metadata": {
        "id": "byIISOn-hZeo"
      },
      "execution_count": 86,
      "outputs": []
    }
  ]
}